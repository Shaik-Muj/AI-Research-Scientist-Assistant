{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic RAG Demo\n",
    "\n",
    "This notebook demonstrates the **Agentic RAG** system for complex research queries with multi-step reasoning.\n",
    "\n",
    "**Agentic RAG** = Agent + Multiple retrievals + Synthesis\n",
    "\n",
    "Perfect for:\n",
    "- Complex research questions\n",
    "- Comparative analysis\n",
    "- Multi-faceted queries\n",
    "- Exploratory research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from agentic_rag import AgenticRAG\n",
    "\n",
    "print(\"[OK] Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Agentic RAG\n",
    "rag = AgenticRAG()\n",
    "\n",
    "print(\"[OK] Agentic RAG initialized with ReAct agent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Comparative Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Compare GRU and LSTM performance on small datasets\"\n",
    "\n",
    "print(f\"Research Question: {question}\")\n",
    "print(\"\\nAgent is thinking and searching...\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "result = rag.query(question)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL ANSWER\")\n",
    "print(\"=\"*80)\n",
    "print(result['answer'])\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n[OK] Completed in {result['num_steps']} reasoning steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Reasoning Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Agent Reasoning Process:\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for i, step in enumerate(result['reasoning_steps'], 1):\n",
    "    print(f\"\\nStep {i}: {step['action']}\")\n",
    "    print(f\"Input: {step['input']}\")\n",
    "    print(f\"Result: {step['observation']}\")\n",
    "\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Multi-Faceted Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the main advantages and disadvantages of GRU compared to LSTM, and in what scenarios should each be used?\"\n",
    "\n",
    "print(f\"Research Question: {question}\")\n",
    "print(\"\\nAgent is analyzing...\\n\")\n",
    "\n",
    "result = rag.query(question)\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(\"-\"*80)\n",
    "print(result['answer'])\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\nAgent used {result['num_steps']} reasoning steps to answer this question\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Trend Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How has the research on GRU models evolved over time? What are the recent trends?\"\n",
    "\n",
    "print(f\"Research Question: {question}\")\n",
    "print(\"\\nAgent is researching...\\n\")\n",
    "\n",
    "result = rag.query(question)\n",
    "\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(\"-\"*80)\n",
    "print(result['answer'])\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Complex Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask your own complex question!\n",
    "your_question = input(\"Enter your complex research question: \")\n",
    "\n",
    "if your_question:\n",
    "    print(\"\\nAgent is working on your question...\\n\")\n",
    "    result = rag.query(your_question)\n",
    "    \n",
    "    print(\"\\nAnswer:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(result['answer'])\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    print(f\"\\n[OK] Agent completed {result['num_steps']} reasoning steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: Basic RAG vs Agentic RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag_query import BasicRAG\n",
    "\n",
    "# Same question to both systems\n",
    "question = \"Compare GRU and LSTM\"\n",
    "\n",
    "print(\"Testing the same question with both systems:\")\n",
    "print(f\"Question: {question}\\n\")\n",
    "\n",
    "# Basic RAG\n",
    "print(\"1. BASIC RAG (single retrieval):\")\n",
    "print(\"-\"*80)\n",
    "basic_rag = BasicRAG()\n",
    "basic_result = basic_rag.query(question, n_results=5)\n",
    "print(basic_result['answer'][:300] + \"...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Agentic RAG\n",
    "print(\"\\n2. AGENTIC RAG (multi-step reasoning):\")\n",
    "print(\"-\"*80)\n",
    "agentic_result = rag.query(question)\n",
    "print(agentic_result['answer'][:300] + \"...\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\nBasic RAG: 1 retrieval step\")\n",
    "print(f\"Agentic RAG: {agentic_result['num_steps']} reasoning steps\")\n",
    "print(\"\\nAgentic RAG provides more comprehensive answers for complex questions!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Agentic RAG** excels at:\n",
    "- Complex multi-step reasoning\n",
    "- Comparative analysis\n",
    "- Synthesizing information from multiple sources\n",
    "- Breaking down complex questions\n",
    "- Iterative refinement\n",
    "\n",
    "**When to use**:\n",
    "- Research questions requiring deep analysis\n",
    "- Comparisons across multiple papers\n",
    "- Trend identification\n",
    "- Exploratory research\n",
    "\n",
    "**Trade-offs**:\n",
    "- Slower than Basic RAG (multiple steps)\n",
    "- More comprehensive answers\n",
    "- Better for complex queries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
